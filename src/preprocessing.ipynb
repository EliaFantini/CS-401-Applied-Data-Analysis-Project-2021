{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import bz2\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speaker_affiliations(parquet_path, out_path, remove_raw=False):\n",
    "\n",
    "    # load speaker info\n",
    "    speaker_info = pd.read_parquet(parquet_path)\n",
    "    speaker_info = speaker_info[[\"id\", \"label\", \"party\"]]\n",
    "\n",
    "    # take the speakers that have an assigned political affiliation\n",
    "    speaker_info = speaker_info.dropna()\n",
    "\n",
    "    # take the first affiliation only (TODO: this is most likely NOT the best method, think what to do when someone has multiple affiliations)\n",
    "    # speaker_info[\"party\"] = speaker_info[\"party\"].apply(lambda x: int(x[0][1:]))\n",
    "\n",
    "    # alternatively (I think a slightly better way), select most common party\n",
    "    speaker_info[\"party\"] = speaker_info[\"party\"].apply(lambda x: mode(x)[1:])\n",
    "\n",
    "    # transform speaker id into int\n",
    "    speaker_info[\"id\"] = speaker_info[\"id\"].apply(lambda x: int(x[1:]))\n",
    "    \n",
    "    print(f\"Speaker affiliation DF:\\n {speaker_info.head()}\")\n",
    "\n",
    "    speaker_info.to_pickle(out_path)\n",
    "\n",
    "    if remove_raw:\n",
    "        os.remove(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(json_path_bz2, pickle_path, remove_raw=False):\n",
    "    data = [] \n",
    "    with bz2.open(json_path_bz2, 'rb') as s_file:\n",
    "        print(\"Quotation file opened...\")\n",
    "        for instance in tqdm(s_file):\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            \n",
    "            # if there is no speaker, skip current row\n",
    "            if not instance['qids']:\n",
    "                continue\n",
    "            \n",
    "            # else proceed to read the data\n",
    "            row = dict()\n",
    "            row['speaker_id'] = int(instance['qids'][0][1:])\n",
    "            row['quote_id'] = instance['quoteID']\n",
    "            row['quotation'] = instance['quotation']\n",
    "            data.append(row)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_pickle(pickle_path)\n",
    "    \n",
    "    if remove_raw:\n",
    "        os.remove(json_path_bz2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_quotes_with_speaker_affiliations(df_quotes, df_affiliations, out_path):\n",
    "    # join the quote data with their corresponding labels\n",
    "    merged = pd.merge(left=df_quotes, left_on=\"speaker_id\", right=df_affiliations, right_on=\"id\")\n",
    "    merged = merged.drop(columns=[\"id\"])\n",
    "    merged = merged.rename(columns = {\"label\": \"speaker\"})\n",
    "    print(f\"Merged DF: \\n{merged.head()}\")\n",
    "    merged.to_pickle(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one time operation - generate a pickle file containing speaker's affiliations\n",
    "PARQUET_PATH = \"../data/raw/speaker_attributes.parquet\"\n",
    "SPEAKER_AFFILIATIONS_OUT_PATH = \"../data/binary/speaker_attributes.pickle\"\n",
    "\n",
    "print(\"Generating speaker affiliations DF...\")\n",
    "if not os.path.exists(SPEAKER_AFFILIATIONS_OUT_PATH):\n",
    "    generate_speaker_affiliations(PARQUET_PATH, SPEAKER_AFFILIATIONS_OUT_PATH)\n",
    "print(\"Done.\\n\")\n",
    "\n",
    "# dataset loading - perform for each batch of the data (2015, 2016, ..., 2020)\n",
    "years = [2019]\n",
    "for year in years:\n",
    "    DATASET_PATH_JSON_BZ2 = f\"../data/raw/quotes-{year}.json.bz2\"\n",
    "    DATASET_PATH_PICKLE = f\"../data/binary/quotes-{year}.pickle\"\n",
    "    MERGED_OUT_PATH = f\"../data/binary/data-{year}.pickle\"\n",
    "\n",
    "    print(\"Generating quotes DF...\")\n",
    "    if not os.path.exists(DATASET_PATH_PICKLE):\n",
    "        save_pickle(DATASET_PATH_JSON_BZ2, DATASET_PATH_PICKLE)\n",
    "    print(\"Done.\\n\")\n",
    "\n",
    "    df_quotes = pd.read_pickle(DATASET_PATH_PICKLE)\n",
    "    df_affiliations = pd.read_pickle(SPEAKER_AFFILIATIONS_OUT_PATH)\n",
    "    \n",
    "    print(\"Generating merged df...\")\n",
    "    if not os.path.exists(MERGED_OUT_PATH):\n",
    "        join_quotes_with_speaker_affiliations(df_quotes, df_affiliations, MERGED_OUT_PATH)\n",
    "    print(\"Done.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "paths = [f\"../data/binary/data-{year}.pickle\" for year in years]\n",
    "dfs = [pd.read_pickle(path) for path in paths]\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df.to_pickle(\"../data/binary/data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining US Politicians dataset\n",
    "To obtain a dataset of US Politician quotations, we proceed to:\n",
    "1. Only keep the quotations where the speaker's party is `29468` (Republican party) or `29552` (Democratic party).\n",
    "2. Filter out the rows that have `None` as a value in the `Candidacy` column in the Wikidata - majority of the speaker's affiliated with the political parties were not actual politicians - they are often celebrities, sport stars, TV personalities, etc. We believe it is beneficial to only take the actual politicians, as they are more likely to speak about actual political matters and represent their party's ideology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional preprocessing to obtain the US politicans data\n",
    "df = pd.read_pickle(\"../data/binary/data.pickle\")\n",
    "# filter to only keep the american politicians\n",
    "df = df[df[\"party\"].isin([29468, 29552])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintain only the quotes where the speakers are actually politicians - they were candidates in at least one election\n",
    "speaker_data = pd.read_parquet(PARQUET_PATH)\n",
    "candidates = speaker_data[[\"id\", \"candidacy\"]]\n",
    "candidates = candidates.dropna()\n",
    "candidates.drop(columns=\"candidacy\")\n",
    "candidates[\"id\"] = candidates[\"id\"].apply(lambda x: int(x[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only keep the ones that actually participated in an election (exclude celebrities etc.)\n",
    "df = pd.merge(left=df, left_on=\"speaker_id\", right_on=\"id\", right=candidates)\n",
    "df = df.drop(columns=[\"id\"])\n",
    "\n",
    "# save\n",
    "df.to_pickle(\"../data/binary/us-politicians.pickle\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ca7bf982d50e176929d33c65df232637f1d4c63720dcda24aee19eb37e3e0c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ada': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

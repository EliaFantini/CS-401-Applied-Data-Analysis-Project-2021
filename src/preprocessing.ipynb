{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speaker_affiliations(parquet_path, out_path, remove_raw=False):\n",
    "\n",
    "    # load speaker info\n",
    "    speaker_info = pd.read_parquet(parquet_path)\n",
    "    speaker_info = speaker_info[[\"id\", \"label\", \"party\"]]\n",
    "\n",
    "    # take the speakers that have an assigned political affiliation\n",
    "    speaker_info = speaker_info.dropna()\n",
    "\n",
    "    # take the first affiliation only (TODO: this is most likely NOT the best method, think what to do when someone has multiple affiliations)\n",
    "    speaker_info[\"party\"] = speaker_info[\"party\"].apply(lambda x: int(x[0][1:]))\n",
    "    speaker_info[\"id\"] = speaker_info[\"id\"].apply(lambda x: int(x[1:]))\n",
    "    \n",
    "    print(f\"Speaker affiliation DF:\\n {speaker_info.head()}\")\n",
    "\n",
    "    speaker_info.to_pickle(out_path)\n",
    "\n",
    "    if remove_raw:\n",
    "        os.remove(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(json_path_bz2, pickle_path, remove_raw=False):\n",
    "    data = [] \n",
    "    with bz2.open(json_path_bz2, 'rb') as s_file:\n",
    "        print(\"Quotation file opened...\")\n",
    "        for instance in tqdm(s_file):\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            \n",
    "            # if there is no speaker, skip current row\n",
    "            if not instance['qids']:\n",
    "                continue\n",
    "            \n",
    "            # else proceed to read the data\n",
    "            row = dict()\n",
    "            row['speaker_id'] = int(instance['qids'][0][1:])\n",
    "            row['quote_id'] = instance['quoteID']\n",
    "            row['quotation'] = instance['quotation']\n",
    "            data.append(row)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_pickle(pickle_path)\n",
    "    \n",
    "    if remove_raw:\n",
    "        os.remove(json_path_bz2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_quotes_with_speaker_affiliations(df_quotes, df_affiliations, out_path):\n",
    "    # join the quote data with their corresponding labels\n",
    "    merged = pd.merge(left=df_quotes, left_on=\"speaker_id\", right=df_affiliations, right_on=\"id\")\n",
    "    merged = merged.drop(columns=[\"id\"])\n",
    "    merged = merged.rename(columns = {\"label\": \"speaker\"})\n",
    "    print(f\"Merged DF: \\n{merged.head()}\")\n",
    "    merged.to_pickle(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speaker affiliations DF...\n",
      "Done.\n",
      "\n",
      "Generating quotes DF...\n",
      "Quotation file opened...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21763302it [20:45, 17478.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "\n",
      "Generating merged df...\n",
      "   speaker_id           quote_id  \\\n",
      "0       22686  2019-04-08-048753   \n",
      "1    42336656  2019-05-15-053302   \n",
      "2    16672061  2019-02-27-055406   \n",
      "3      809063  2019-12-08-023053   \n",
      "4     1971786  2019-02-21-000088   \n",
      "\n",
      "                                           quotation  \n",
      "0       It is immoral. It is harmful. It is hurtful.  \n",
      "1  It is important for our equine science student...  \n",
      "2  It is important to many Native American tribes...  \n",
      "3  It is impossible, biologically, truly to `rest...  \n",
      "4  [ Chilton ] put it on a little tape recorder a...  \n",
      "     id                    label    party\n",
      "0    23        George Washington   327591\n",
      "3   207           George W. Bush    29468\n",
      "5   368         Augusto Pinochet   327591\n",
      "11  815  Gabriel Gonz√°les Videla  1759368\n",
      "14  873             Meryl Streep    29552\n",
      "Merged DF: \n",
      "   speaker_id           quote_id  \\\n",
      "0       22686  2019-04-08-048753   \n",
      "1       22686  2019-05-26-025817   \n",
      "2       22686  2019-03-20-001438   \n",
      "3       22686  2019-03-29-004685   \n",
      "4       22686  2019-07-23-003672   \n",
      "\n",
      "                                           quotation       speaker  party  \n",
      "0       It is immoral. It is harmful. It is hurtful.  Donald Trump  29468  \n",
      "1  It is where they want to be and where they sho...  Donald Trump  29468  \n",
      "2  a horrible, disgraceful thing and a horrible act.  Donald Trump  29468  \n",
      "3  Allies expressed their support for the secreta...  Donald Trump  29468  \n",
      "4  And if I can help, I would love to be a mediator.  Donald Trump  29468  \n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one time operation - generate a pickle file containing speaker's affiliations\n",
    "PARQUET_PATH = \"../data/raw/speaker_attributes.parquet\"\n",
    "SPEAKER_AFFILIATIONS_OUT_PATH = \"../data/binary/speaker_attributes.pickle\"\n",
    "\n",
    "print(\"Generating speaker affiliations DF...\")\n",
    "if not os.path.exists(SPEAKER_AFFILIATIONS_OUT_PATH):\n",
    "    generate_speaker_affiliations(PARQUET_PATH, SPEAKER_AFFILIATIONS_OUT_PATH)\n",
    "print(\"Done.\\n\")\n",
    "\n",
    "# dataset loading - perform for each batch of the data (2015, 2016, ..., 2020)\n",
    "years = [2019]\n",
    "for year in years:\n",
    "    DATASET_PATH_JSON_BZ2 = f\"../data/raw/quotes-{year}.json.bz2\"\n",
    "    DATASET_PATH_PICKLE = f\"../data/binary/quotes-{year}.pickle\"\n",
    "    MERGED_OUT_PATH = f\"../data/binary/data-{year}.pickle\"\n",
    "\n",
    "    print(\"Generating quotes DF...\")\n",
    "    if not os.path.exists(DATASET_PATH_PICKLE):\n",
    "        save_pickle(DATASET_PATH_JSON_BZ2, DATASET_PATH_PICKLE)\n",
    "    print(\"Done.\\n\")\n",
    "\n",
    "    df_quotes = pd.read_pickle(DATASET_PATH_PICKLE)\n",
    "    df_affiliations = pd.read_pickle(SPEAKER_AFFILIATIONS_OUT_PATH)\n",
    "    \n",
    "    print(\"Generating merged df...\")\n",
    "    if not os.path.exists(MERGED_OUT_PATH):\n",
    "        join_quotes_with_speaker_affiliations(df_quotes, df_affiliations, MERGED_OUT_PATH)\n",
    "    print(\"Done.\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ca7bf982d50e176929d33c65df232637f1d4c63720dcda24aee19eb37e3e0c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ada': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
